(.venv) C:\Users\Acer\Desktop\GITHUB_DEAN\dean_codelab>python -m face_vit_phq.train
Using device: cuda
Number of GPUs available: 1
Current GPU: NVIDIA GeForce RTX 3060 Laptop GPU
Loading dataset from deanngkl/ferplus-7cls (split=train) ...
Loaded dataset from deanngkl/ferplus-7cls (split=train), length=35481
Loaded 35481 samples from deanngkl/ferplus-7cls
Loading dataset from deanngkl/ferplus-7cls (split=validation) ...
No explicit validation split for deanngkl/ferplus-7cls, doing manual split.
Loading dataset from deanngkl/affectnet_no_contempt (split=train) ...
Loaded dataset from deanngkl/affectnet_no_contempt (split=train), length=27823
Loaded 27823 samples from deanngkl/affectnet_no_contempt
Loading dataset from deanngkl/affectnet_no_contempt (split=validation) ...
No explicit validation split for deanngkl/affectnet_no_contempt, doing manual split.
Loading dataset from deanngkl/raf-db-7emotions (split=train) ...
Loaded dataset from deanngkl/raf-db-7emotions (split=train), length=20471
Loaded 20471 samples from deanngkl/raf-db-7emotions
Loading dataset from deanngkl/raf-db-7emotions (split=validation) ...
No explicit validation split for deanngkl/raf-db-7emotions, doing manual split.
Loaded 75398 training samples from 3 sources
Loaded 8377 validation samples from 3 sources
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/vit_tiny_patch16_224.augreg_in21k_ft_in1k)
INFO:timm.models._hub:[timm/vit_tiny_patch16_224.augreg_in21k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
Using optimizer: AdamW with learning rate 0.0003
2025-06-05 12:17:07.913929: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-06-05 12:17:13.079783: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
DataLoader sanity-check â€¦
First batch loaded: torch.Size([64, 3, 224, 224]), targets: torch.Size([64]), Unique targets: tensor([0, 1, 2, 3, 4, 5, 6])
DataLoader test passed. Starting training loop...
Epoch 1 started at 2025-06-05 12:18:03
c:\Users\Acer\Desktop\GITHUB_DEAN\dean_codelab\.venv\Lib\site-packages\timm\models\vision_transformer.py:93: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\aten\src\ATen\native\transformers\cuda\sdp_utils.cpp:263.)
  x = F.scaled_dot_product_attention(
c:\Users\Acer\Desktop\GITHUB_DEAN\dean_codelab\.venv\Lib\site-packages\torch\optim\lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
Epoch 1 finished at 2025-06-05 12:21:39
Epoch [1/60], Train Loss: 1.2238, Train Accuracy: 0.5427, Time: 00:03:36
LR end-of-epoch: 3.00e-04
Epoch [1/60]  train_loss=1.2238  val_loss=0.7531  val_acc=0.7186  LR=3.00e-04
Epoch 2 started at 2025-06-05 12:22:54
Epoch 2 finished at 2025-06-05 12:29:10
Epoch [2/60], Train Loss: 1.0290, Train Accuracy: 0.6131, Time: 00:06:16
LR end-of-epoch: 2.99e-04
Epoch [2/60]  train_loss=1.0290  val_loss=0.7090  val_acc=0.7386  LR=2.99e-04
Best model saved at face_vit_phq/output\best_model_epoch_2.pth
Epoch 3 started at 2025-06-05 12:30:51
Epoch 3 finished at 2025-06-05 12:36:13
Epoch [3/60], Train Loss: 0.9386, Train Accuracy: 0.6504, Time: 00:05:21
LR end-of-epoch: 2.98e-04
Epoch [3/60]  train_loss=0.9386  val_loss=0.6973  val_acc=0.7339  LR=2.98e-04
Best model saved at face_vit_phq/output\best_model_epoch_3.pth
Epoch 4 started at 2025-06-05 12:37:03
Epoch 4 finished at 2025-06-05 12:41:06
Epoch [4/60], Train Loss: 0.8939, Train Accuracy: 0.6725, Time: 00:04:03
LR end-of-epoch: 2.96e-04
Epoch [4/60]  train_loss=0.8939  val_loss=0.6995  val_acc=0.7411  LR=2.96e-04
Epoch 5 started at 2025-06-05 12:42:14
Epoch 5 finished at 2025-06-05 12:48:52
Epoch [5/60], Train Loss: 0.8397, Train Accuracy: 0.6949, Time: 00:06:38
LR end-of-epoch: 2.94e-04
Epoch [5/60]  train_loss=0.8397  val_loss=0.6822  val_acc=0.7522  LR=2.94e-04
              precision    recall  f1-score   support

           0      0.628     0.715     0.669      1076
           1      0.392     0.709     0.505       402
           2      0.519     0.680     0.589       482
           3      0.943     0.846     0.892      2063
           4      0.886     0.812     0.848      2321
           5      0.697     0.583     0.635      1046
           6      0.721     0.688     0.704       987

    accuracy                          0.752      8377
   macro avg      0.684     0.719     0.692      8377
weighted avg      0.779     0.752     0.761      8377

Best model saved at face_vit_phq/output\best_model_epoch_5.pth
Epoch 6 started at 2025-06-05 12:50:23
Epoch 6 finished at 2025-06-05 12:56:46
Epoch [6/60], Train Loss: 0.7996, Train Accuracy: 0.7094, Time: 00:06:23
LR end-of-epoch: 2.91e-04
Epoch [6/60]  train_loss=0.7996  val_loss=0.6511  val_acc=0.7609  LR=2.91e-04
Best model saved at face_vit_phq/output\best_model_epoch_6.pth
Epoch 7 started at 2025-06-05 12:58:22
Epoch 7 finished at 2025-06-05 13:05:00
Epoch [7/60], Train Loss: 0.8114, Train Accuracy: 0.7057, Time: 00:06:38
LR end-of-epoch: 2.88e-04
Epoch [7/60]  train_loss=0.8114  val_loss=0.6735  val_acc=0.7559  LR=2.88e-04
Best model saved at face_vit_phq/output\best_model_epoch_7.pth
Epoch 8 started at 2025-06-05 13:06:29
Epoch 8 finished at 2025-06-05 13:11:55
Epoch [8/60], Train Loss: 0.7719, Train Accuracy: 0.7168, Time: 00:05:26
LR end-of-epoch: 2.85e-04
Epoch [8/60]  train_loss=0.7719  val_loss=0.6528  val_acc=0.7615  LR=2.85e-04
Epoch 9 started at 2025-06-05 13:13:18
Epoch 9 finished at 2025-06-05 13:17:09
Epoch [9/60], Train Loss: 0.7605, Train Accuracy: 0.7224, Time: 00:03:50
LR end-of-epoch: 2.81e-04
Epoch [9/60]  train_loss=0.7605  val_loss=0.6763  val_acc=0.7647  LR=2.81e-04
Best model saved at face_vit_phq/output\best_model_epoch_9.pth
Epoch 10 started at 2025-06-05 13:17:56
Epoch 10 finished at 2025-06-05 13:21:34
Epoch [10/60], Train Loss: 0.7138, Train Accuracy: 0.7392, Time: 00:03:38
LR end-of-epoch: 2.76e-04
Epoch [10/60]  train_loss=0.7138  val_loss=0.6223  val_acc=0.7805  LR=2.76e-04
              precision    recall  f1-score   support

           0      0.671     0.751     0.708      1076
           1      0.562     0.560     0.561       402
           2      0.493     0.712     0.582       482
           3      0.955     0.865     0.908      2063
           4      0.842     0.907     0.873      2321
           5      0.739     0.596     0.660      1046
           6      0.751     0.659     0.702       987

    accuracy                          0.780      8377
   macro avg      0.716     0.721     0.713      8377
weighted avg      0.791     0.780     0.782      8377

Best model saved at face_vit_phq/output\best_model_epoch_10.pth
Epoch 11 started at 2025-06-05 13:22:43
Epoch 11 finished at 2025-06-05 13:26:43
Epoch [11/60], Train Loss: 0.6839, Train Accuracy: 0.7520, Time: 00:04:00
LR end-of-epoch: 2.71e-04
Epoch [11/60]  train_loss=0.6839  val_loss=0.6414  val_acc=0.7691  LR=2.71e-04
Best model saved at face_vit_phq/output\best_model_epoch_11.pth
Epoch 12 started at 2025-06-05 13:27:46
Epoch 12 finished at 2025-06-05 13:31:42
Epoch [12/60], Train Loss: 0.6639, Train Accuracy: 0.7664, Time: 00:03:56
LR end-of-epoch: 2.66e-04
Epoch [12/60]  train_loss=0.6639  val_loss=0.6424  val_acc=0.7799  LR=2.66e-04
Epoch 13 started at 2025-06-05 13:32:46
Epoch 13 finished at 2025-06-05 13:37:13
Epoch [13/60], Train Loss: 0.6360, Train Accuracy: 0.7647, Time: 00:04:26
LR end-of-epoch: 2.61e-04
Epoch [13/60]  train_loss=0.6360  val_loss=0.6440  val_acc=0.7882  LR=2.61e-04
Epoch 14 started at 2025-06-05 13:38:16
Epoch 14 finished at 2025-06-05 13:42:17
Epoch [14/60], Train Loss: 0.6011, Train Accuracy: 0.7831, Time: 00:04:01
LR end-of-epoch: 2.55e-04
Epoch [14/60]  train_loss=0.6011  val_loss=0.6834  val_acc=0.7660  LR=2.55e-04
Best model saved at face_vit_phq/output\best_model_epoch_14.pth
Epoch 15 started at 2025-06-05 13:43:21
Epoch 15 finished at 2025-06-05 13:47:17
Epoch [15/60], Train Loss: 0.5986, Train Accuracy: 0.7882, Time: 00:03:56
LR end-of-epoch: 2.48e-04
Epoch [15/60]  train_loss=0.5986  val_loss=0.6526  val_acc=0.7836  LR=2.48e-04
              precision    recall  f1-score   support

           0      0.701     0.717     0.709      1076
           1      0.559     0.587     0.573       402
           2      0.522     0.666     0.585       482
           3      0.947     0.895     0.920      2063
           4      0.881     0.860     0.871      2321
           5      0.701     0.620     0.658      1046
           6      0.678     0.754     0.714       987

    accuracy                          0.784      8377
   macro avg      0.713     0.728     0.718      8377
weighted avg      0.792     0.784     0.786      8377

Epoch 16 started at 2025-06-05 13:48:21
Epoch 16 finished at 2025-06-05 13:52:14
Epoch [16/60], Train Loss: 0.5633, Train Accuracy: 0.7917, Time: 00:03:52
LR end-of-epoch: 2.42e-04
Epoch [16/60]  train_loss=0.5633  val_loss=0.7103  val_acc=0.7814  LR=2.42e-04
Epoch 17 started at 2025-06-05 13:53:21
Epoch 17 finished at 2025-06-05 13:57:18
Epoch [17/60], Train Loss: 0.5677, Train Accuracy: 0.7953, Time: 00:03:57
LR end-of-epoch: 2.35e-04
Epoch [17/60]  train_loss=0.5677  val_loss=0.6742  val_acc=0.7801  LR=2.35e-04
Epoch 18 started at 2025-06-05 13:58:23
Epoch 18 finished at 2025-06-05 14:02:30
Epoch [18/60], Train Loss: 0.5483, Train Accuracy: 0.8052, Time: 00:04:07
LR end-of-epoch: 2.28e-04
Epoch [18/60]  train_loss=0.5483  val_loss=0.7194  val_acc=0.7823  LR=2.28e-04
Epoch 19 started at 2025-06-05 14:03:34
Epoch 19 finished at 2025-06-05 14:07:44
Epoch [19/60], Train Loss: 0.5292, Train Accuracy: 0.8146, Time: 00:04:09
LR end-of-epoch: 2.20e-04
Epoch [19/60]  train_loss=0.5292  val_loss=0.6942  val_acc=0.7905  LR=2.20e-04
Epoch 20 started at 2025-06-05 14:08:47
Epoch 20 finished at 2025-06-05 14:12:56
Epoch [20/60], Train Loss: 0.5174, Train Accuracy: 0.8089, Time: 00:04:09
LR end-of-epoch: 2.13e-04
Epoch [20/60]  train_loss=0.5174  val_loss=0.7327  val_acc=0.7897  LR=2.13e-04
              precision    recall  f1-score   support

           0      0.745     0.688     0.715      1076
           1      0.571     0.580     0.575       402
           2      0.544     0.629     0.583       482
           3      0.930     0.906     0.918      2063
           4      0.891     0.869     0.880      2321
           5      0.663     0.701     0.682      1046
           6      0.692     0.730     0.711       987

    accuracy                          0.790      8377
   macro avg      0.720     0.729     0.723      8377
weighted avg      0.795     0.790     0.792      8377

Best model saved at face_vit_phq/output\best_model_epoch_20.pth
Epoch 21 started at 2025-06-05 14:14:01
Epoch 21 finished at 2025-06-05 14:18:14
Epoch [21/60], Train Loss: 0.5087, Train Accuracy: 0.8182, Time: 00:04:13
LR end-of-epoch: 2.05e-04
Epoch [21/60]  train_loss=0.5087  val_loss=0.7234  val_acc=0.7887  LR=2.05e-04
Epoch 22 started at 2025-06-05 14:19:18
Epoch 22 finished at 2025-06-05 14:23:14
Epoch [22/60], Train Loss: 0.4890, Train Accuracy: 0.8243, Time: 00:03:55
LR end-of-epoch: 1.97e-04
Epoch [22/60]  train_loss=0.4890  val_loss=0.7697  val_acc=0.7941  LR=1.97e-04
Epoch 23 started at 2025-06-05 14:24:19
Epoch 23 finished at 2025-06-05 14:28:29
Epoch [23/60], Train Loss: 0.4632, Train Accuracy: 0.8297, Time: 00:04:10
LR end-of-epoch: 1.89e-04
Epoch [23/60]  train_loss=0.4632  val_loss=0.7472  val_acc=0.7907  LR=1.89e-04
Best model saved at face_vit_phq/output\best_model_epoch_23.pth
Epoch 24 started at 2025-06-05 14:29:37
Epoch 24 finished at 2025-06-05 14:33:30
Epoch [24/60], Train Loss: 0.4539, Train Accuracy: 0.8386, Time: 00:03:53
LR end-of-epoch: 1.80e-04
Epoch [24/60]  train_loss=0.4539  val_loss=0.7722  val_acc=0.7863  LR=1.80e-04
Epoch 25 started at 2025-06-05 14:34:35
Epoch 25 finished at 2025-06-05 14:38:29
Epoch [25/60], Train Loss: 0.4409, Train Accuracy: 0.8385, Time: 00:03:53
LR end-of-epoch: 1.72e-04
Epoch [25/60]  train_loss=0.4409  val_loss=0.8574  val_acc=0.7934  LR=1.72e-04
              precision    recall  f1-score   support

           0      0.757     0.631     0.688      1076
           1      0.589     0.600     0.594       402
           2      0.597     0.585     0.591       482
           3      0.911     0.919     0.915      2063
           4      0.866     0.916     0.890      2321
           5      0.676     0.678     0.677      1046
           6      0.705     0.723     0.714       987

    accuracy                          0.793      8377
   macro avg      0.729     0.722     0.724      8377
weighted avg      0.791     0.793     0.791      8377

Epoch 26 started at 2025-06-05 14:39:33
Epoch 26 finished at 2025-06-05 14:43:22
Epoch [26/60], Train Loss: 0.4674, Train Accuracy: 0.8336, Time: 00:03:49
LR end-of-epoch: 1.63e-04
Epoch [26/60]  train_loss=0.4674  val_loss=0.8400  val_acc=0.7856  LR=1.63e-04
Epoch 27 started at 2025-06-05 14:44:25
Epoch 27 finished at 2025-06-05 14:48:13
Epoch [27/60], Train Loss: 0.4229, Train Accuracy: 0.8426, Time: 00:03:48
LR end-of-epoch: 1.55e-04
Epoch [27/60]  train_loss=0.4229  val_loss=0.8464  val_acc=0.7882  LR=1.55e-04
Epoch 28 started at 2025-06-05 14:49:15
Epoch 28 finished at 2025-06-05 14:53:08
Epoch [28/60], Train Loss: 0.4405, Train Accuracy: 0.8349, Time: 00:03:53
LR end-of-epoch: 1.46e-04
Epoch [28/60]  train_loss=0.4405  val_loss=0.8289  val_acc=0.7981  LR=1.46e-04
Epoch 29 started at 2025-06-05 14:54:15
Epoch 29 finished at 2025-06-05 14:58:09
Epoch [29/60], Train Loss: 0.4111, Train Accuracy: 0.8406, Time: 00:03:54
LR end-of-epoch: 1.38e-04
Epoch [29/60]  train_loss=0.4111  val_loss=0.8715  val_acc=0.7995  LR=1.38e-04
Best model saved at face_vit_phq/output\best_model_epoch_29.pth
Epoch 30 started at 2025-06-05 14:58:59
Epoch 30 finished at 2025-06-05 15:02:50
Epoch [30/60], Train Loss: 0.4056, Train Accuracy: 0.8555, Time: 00:03:50
LR end-of-epoch: 1.29e-04
Epoch [30/60]  train_loss=0.4056  val_loss=0.8645  val_acc=0.8016  LR=1.29e-04
              precision    recall  f1-score   support

           0      0.711     0.730     0.721      1076
           1      0.667     0.478     0.557       402
           2      0.544     0.598     0.570       482
           3      0.941     0.909     0.925      2063
           4      0.890     0.891     0.891      2321
           5      0.727     0.684     0.705      1046
           6      0.685     0.800     0.738       987

    accuracy                          0.802      8377
   macro avg      0.738     0.727     0.729      8377
weighted avg      0.804     0.802     0.801      8377

Best model saved at face_vit_phq/output\best_model_epoch_30.pth
Epoch 31 started at 2025-06-05 15:03:37
Epoch 31 finished at 2025-06-05 15:08:31
Epoch [31/60], Train Loss: 0.4069, Train Accuracy: 0.8521, Time: 00:04:53
LR end-of-epoch: 1.21e-04
Epoch [31/60]  train_loss=0.4069  val_loss=0.8765  val_acc=0.7978  LR=1.21e-04
Best model saved at face_vit_phq/output\best_model_epoch_31.pth
Epoch 32 started at 2025-06-05 15:10:04
Epoch 32 finished at 2025-06-05 15:14:29
Epoch [32/60], Train Loss: 0.3778, Train Accuracy: 0.8627, Time: 00:04:24
LR end-of-epoch: 1.13e-04
Epoch [32/60]  train_loss=0.3778  val_loss=0.9290  val_acc=0.8052  LR=1.13e-04
Epoch 33 started at 2025-06-05 15:15:34
Epoch 33 finished at 2025-06-05 15:19:49
Epoch [33/60], Train Loss: 0.3955, Train Accuracy: 0.8539, Time: 00:04:14
LR end-of-epoch: 1.04e-04
Epoch [33/60]  train_loss=0.3955  val_loss=0.9216  val_acc=0.8027  LR=1.04e-04
Best model saved at face_vit_phq/output\best_model_epoch_33.pth
Epoch 34 started at 2025-06-05 15:20:39
Epoch 34 finished at 2025-06-05 15:27:47
Epoch [34/60], Train Loss: 0.3858, Train Accuracy: 0.8545, Time: 00:07:07
LR end-of-epoch: 9.63e-05
Epoch [34/60]  train_loss=0.3858  val_loss=0.9443  val_acc=0.8014  LR=9.63e-05
Epoch 35 started at 2025-06-05 15:29:32
Epoch 35 finished at 2025-06-05 15:36:30
Epoch [35/60], Train Loss: 0.3675, Train Accuracy: 0.8574, Time: 00:06:58
LR end-of-epoch: 8.84e-05
Epoch [35/60]  train_loss=0.3675  val_loss=0.9562  val_acc=0.8032  LR=8.84e-05
              precision    recall  f1-score   support

           0      0.711     0.737     0.724      1076
           1      0.646     0.485     0.554       402
           2      0.574     0.602     0.588       482
           3      0.932     0.915     0.924      2063
           4      0.874     0.919     0.896      2321
           5      0.726     0.658     0.690      1046
           6      0.712     0.750     0.730       987

    accuracy                          0.803      8377
   macro avg      0.739     0.724     0.729      8377
weighted avg      0.802     0.803     0.801      8377

Epoch 36 started at 2025-06-05 15:38:19
Epoch 36 finished at 2025-06-05 15:45:09
Epoch [36/60], Train Loss: 0.3710, Train Accuracy: 0.8625, Time: 00:06:50
LR end-of-epoch: 8.08e-05
Epoch [36/60]  train_loss=0.3710  val_loss=0.9255  val_acc=0.8034  LR=8.08e-05
Epoch 37 started at 2025-06-05 15:46:42
Epoch 37 finished at 2025-06-05 15:53:06
Epoch [37/60], Train Loss: 0.3383, Train Accuracy: 0.8768, Time: 00:06:24
LR end-of-epoch: 7.33e-05
Epoch [37/60]  train_loss=0.3383  val_loss=1.0069  val_acc=0.8042  LR=7.33e-05
Epoch 38 started at 2025-06-05 15:54:16
Epoch 38 finished at 2025-06-05 15:58:39
Epoch [38/60], Train Loss: 0.3356, Train Accuracy: 0.8726, Time: 00:04:23
LR end-of-epoch: 6.61e-05
Epoch [38/60]  train_loss=0.3356  val_loss=1.0344  val_acc=0.8055  LR=6.61e-05
Epoch 39 started at 2025-06-05 15:59:34
Epoch 39 finished at 2025-06-05 16:04:00
Epoch [39/60], Train Loss: 0.3311, Train Accuracy: 0.8704, Time: 00:04:25
LR end-of-epoch: 5.92e-05
Epoch [39/60]  train_loss=0.3311  val_loss=1.0183  val_acc=0.8125  LR=5.92e-05
Best model saved at face_vit_phq/output\best_model_epoch_39.pth
Epoch 40 started at 2025-06-05 16:04:45
Epoch 40 finished at 2025-06-05 16:08:16
Epoch [40/60], Train Loss: 0.3285, Train Accuracy: 0.8672, Time: 00:03:30
LR end-of-epoch: 5.26e-05
Epoch [40/60]  train_loss=0.3285  val_loss=1.0460  val_acc=0.8079  LR=5.26e-05
              precision    recall  f1-score   support

           0      0.709     0.753     0.730      1076
           1      0.654     0.498     0.565       402
           2      0.614     0.558     0.585       482
           3      0.934     0.922     0.928      2063
           4      0.881     0.919     0.900      2321
           5      0.683     0.707     0.695      1046
           6      0.752     0.722     0.737       987

    accuracy                          0.808      8377
   macro avg      0.747     0.726     0.734      8377
weighted avg      0.806     0.808     0.806      8377

Best model saved at face_vit_phq/output\best_model_epoch_40.pth
Epoch 41 started at 2025-06-05 16:09:02
Epoch 41 finished at 2025-06-05 16:12:32
Epoch [41/60], Train Loss: 0.3484, Train Accuracy: 0.8619, Time: 00:03:30
LR end-of-epoch: 4.63e-05
Epoch [41/60]  train_loss=0.3484  val_loss=1.0561  val_acc=0.8110  LR=4.63e-05
Epoch 42 started at 2025-06-05 16:13:19
Epoch 42 finished at 2025-06-05 16:17:01
Epoch [42/60], Train Loss: 0.3116, Train Accuracy: 0.8759, Time: 00:03:42
LR end-of-epoch: 4.04e-05
Epoch [42/60]  train_loss=0.3116  val_loss=1.0702  val_acc=0.8094  LR=4.04e-05
Epoch 43 started at 2025-06-05 16:17:51
Epoch 43 finished at 2025-06-05 16:23:35
Epoch [43/60], Train Loss: 0.3100, Train Accuracy: 0.8891, Time: 00:05:44
LR end-of-epoch: 3.48e-05
Epoch [43/60]  train_loss=0.3100  val_loss=1.0638  val_acc=0.8126  LR=3.48e-05
Epoch 44 started at 2025-06-05 16:24:39
Epoch 44 finished at 2025-06-05 16:28:29
Epoch [44/60], Train Loss: 0.3087, Train Accuracy: 0.8699, Time: 00:03:49
LR end-of-epoch: 2.96e-05
Epoch [44/60]  train_loss=0.3087  val_loss=1.1194  val_acc=0.8077  LR=2.96e-05
Best model saved at face_vit_phq/output\best_model_epoch_44.pth
Epoch 45 started at 2025-06-05 16:29:31
Epoch 45 finished at 2025-06-05 16:33:47
Epoch [45/60], Train Loss: 0.3116, Train Accuracy: 0.8750, Time: 00:04:15
LR end-of-epoch: 2.48e-05
Epoch [45/60]  train_loss=0.3116  val_loss=1.0913  val_acc=0.8094  LR=2.48e-05
              precision    recall  f1-score   support

           0      0.720     0.735     0.728      1076
           1      0.650     0.527     0.582       402
           2      0.592     0.550     0.570       482
           3      0.939     0.918     0.928      2063
           4      0.877     0.934     0.905      2321
           5      0.729     0.688     0.708      1046
           6      0.710     0.740     0.725       987

    accuracy                          0.809      8377
   macro avg      0.745     0.727     0.735      8377
weighted avg      0.807     0.809     0.807      8377

Epoch 46 started at 2025-06-05 16:34:46
Epoch 46 finished at 2025-06-05 16:38:54
Epoch [46/60], Train Loss: 0.3142, Train Accuracy: 0.8809, Time: 00:04:07
LR end-of-epoch: 2.03e-05
Epoch [46/60]  train_loss=0.3142  val_loss=1.1057  val_acc=0.8160  LR=2.03e-05
Epoch 47 started at 2025-06-05 16:39:54
Epoch 47 finished at 2025-06-05 16:43:47
Epoch [47/60], Train Loss: 0.3259, Train Accuracy: 0.8732, Time: 00:03:52
LR end-of-epoch: 1.64e-05
Epoch [47/60]  train_loss=0.3259  val_loss=1.1178  val_acc=0.8101  LR=1.64e-05
Best model saved at face_vit_phq/output\best_model_epoch_47.pth
Epoch 48 started at 2025-06-05 16:44:49
Epoch 48 finished at 2025-06-05 16:49:08
Epoch [48/60], Train Loss: 0.3329, Train Accuracy: 0.8681, Time: 00:04:18
LR end-of-epoch: 1.28e-05
Epoch [48/60]  train_loss=0.3329  val_loss=1.1397  val_acc=0.8100  LR=1.28e-05
Epoch 49 started at 2025-06-05 16:50:11
Epoch 49 finished at 2025-06-05 16:54:22
Epoch [49/60], Train Loss: 0.3247, Train Accuracy: 0.8656, Time: 00:04:11
LR end-of-epoch: 9.71e-06
Epoch [49/60]  train_loss=0.3247  val_loss=1.1400  val_acc=0.8103  LR=9.71e-06
Epoch 50 started at 2025-06-05 16:55:24
Epoch 50 finished at 2025-06-05 16:59:36
Epoch [50/60], Train Loss: 0.3109, Train Accuracy: 0.8718, Time: 00:04:11
LR end-of-epoch: 7.07e-06
Epoch [50/60]  train_loss=0.3109  val_loss=1.1546  val_acc=0.8070  LR=7.07e-06
              precision    recall  f1-score   support

           0      0.695     0.743     0.718      1076
           1      0.660     0.502     0.571       402
           2      0.582     0.546     0.563       482
           3      0.935     0.916     0.926      2063
           4      0.877     0.928     0.902      2321
           5      0.723     0.693     0.708      1046
           6      0.735     0.738     0.736       987

    accuracy                          0.807      8377
   macro avg      0.744     0.724     0.732      8377
weighted avg      0.805     0.807     0.805      8377

Epoch 51 started at 2025-06-05 17:00:38
Epoch 51 finished at 2025-06-05 17:04:35
Epoch [51/60], Train Loss: 0.3062, Train Accuracy: 0.8829, Time: 00:03:56
LR end-of-epoch: 4.89e-06
Epoch [51/60]  train_loss=0.3062  val_loss=1.1524  val_acc=0.8108  LR=4.89e-06
Epoch 52 started at 2025-06-05 17:05:35
Epoch 52 finished at 2025-06-05 17:09:46
Epoch [52/60], Train Loss: 0.2864, Train Accuracy: 0.8909, Time: 00:04:10
LR end-of-epoch: 3.20e-06
Epoch [52/60]  train_loss=0.2864  val_loss=1.1373  val_acc=0.8103  LR=3.20e-06
Epoch 53 started at 2025-06-05 17:10:51
Epoch 53 finished at 2025-06-05 17:14:59
Epoch [53/60], Train Loss: 0.3083, Train Accuracy: 0.8685, Time: 00:04:08
LR end-of-epoch: 1.98e-06
Epoch [53/60]  train_loss=0.3083  val_loss=1.1673  val_acc=0.8077  LR=1.98e-06
Epoch 54 started at 2025-06-05 17:15:59
Epoch 54 finished at 2025-06-05 17:19:52
Epoch [54/60], Train Loss: 0.2998, Train Accuracy: 0.8821, Time: 00:03:53
LR end-of-epoch: 1.25e-06
Epoch [54/60]  train_loss=0.2998  val_loss=1.1486  val_acc=0.8137  LR=1.25e-06
Epoch 55 started at 2025-06-05 17:20:51
Epoch 55 finished at 2025-06-05 17:25:10
Epoch [55/60], Train Loss: 0.2921, Train Accuracy: 0.8753, Time: 00:04:19
LR end-of-epoch: 1.00e-06
Epoch [55/60]  train_loss=0.2921  val_loss=1.1737  val_acc=0.8116  LR=1.00e-06
              precision    recall  f1-score   support

           0      0.709     0.743     0.726      1076
           1      0.657     0.520     0.581       402
           2      0.631     0.564     0.596       482
           3      0.934     0.922     0.928      2063
           4      0.875     0.929     0.902      2321
           5      0.725     0.700     0.712      1046
           6      0.734     0.737     0.735       987

    accuracy                          0.812      8377
   macro avg      0.752     0.731     0.740      8377
weighted avg      0.809     0.812     0.809      8377

Epoch 56 started at 2025-06-05 17:26:00
Epoch 56 finished at 2025-06-05 17:29:52
Epoch [56/60], Train Loss: 0.3055, Train Accuracy: 0.8714, Time: 00:03:52
LR end-of-epoch: 1.24e-06
Epoch [56/60]  train_loss=0.3055  val_loss=1.1510  val_acc=0.8131  LR=1.24e-06
Epoch 57 started at 2025-06-05 17:30:42
Epoch 57 finished at 2025-06-05 17:34:37
Epoch [57/60], Train Loss: 0.2828, Train Accuracy: 0.8941, Time: 00:03:54
LR end-of-epoch: 1.97e-06
Epoch [57/60]  train_loss=0.2828  val_loss=1.1563  val_acc=0.8132  LR=1.97e-06
Epoch 58 started at 2025-06-05 17:35:25
Epoch 58 finished at 2025-06-05 17:39:38
Epoch [58/60], Train Loss: 0.3050, Train Accuracy: 0.8747, Time: 00:04:12
LR end-of-epoch: 3.18e-06
Epoch [58/60]  train_loss=0.3050  val_loss=1.1743  val_acc=0.8107  LR=3.18e-06
Epoch 59 started at 2025-06-05 17:40:39
Epoch 59 finished at 2025-06-05 17:44:36
Epoch [59/60], Train Loss: 0.3239, Train Accuracy: 0.8724, Time: 00:03:56
LR end-of-epoch: 4.88e-06
Epoch [59/60]  train_loss=0.3239  val_loss=1.1866  val_acc=0.8107  LR=4.88e-06
Epoch 60 started at 2025-06-05 17:45:41
Epoch 60 finished at 2025-06-05 17:50:17
Epoch [60/60], Train Loss: 0.2962, Train Accuracy: 0.8766, Time: 00:04:36
LR end-of-epoch: 7.05e-06
Epoch [60/60]  train_loss=0.2962  val_loss=1.1508  val_acc=0.8145  LR=7.05e-06
              precision    recall  f1-score   support

           0      0.724     0.757     0.740      1076
           1      0.679     0.505     0.579       402
           2      0.632     0.535     0.580       482
           3      0.939     0.922     0.931      2063
           4      0.879     0.932     0.905      2321
           5      0.720     0.702     0.711      1046
           6      0.720     0.757     0.738       987

    accuracy                          0.814      8377
   macro avg      0.756     0.730     0.740      8377
weighted avg      0.811     0.814     0.812      8377

Final model saved at face_vit_phq/output\final_model.pth
Training complete.